{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b788695-e41a-4a02-8e62-6b1b8359990a",
   "metadata": {},
   "source": [
    "### Importing libraries and Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47e96a00-df44-4bb0-8200-553a577f4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "file_path = \"./HousingData.csv\"\n",
    "boston_data = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e00d01-c47e-482b-99e9-899bda5e0a4d",
   "metadata": {},
   "source": [
    "### Defining the Variables and Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e2a88e7-37b1-4db3-a57b-f56396ee5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "median_crime_rate = boston_data['CRIM'].median()\n",
    "boston_data['High_CRIM'] = (boston_data['CRIM'] > median_crime_rate).astype(int)\n",
    "\n",
    "# Drop the original CRIM column\n",
    "boston_data = boston_data.drop(columns=['CRIM'])\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "boston_data_imputed = pd.DataFrame(imputer.fit_transform(boston_data), columns=boston_data.columns)\n",
    "\n",
    "# Define features and target variable\n",
    "X = boston_data_imputed.drop(columns=['High_CRIM'])\n",
    "y = boston_data_imputed['High_CRIM']\n",
    "\n",
    "# Split into training and test sets and standradize the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ae84c-9909-427e-92b5-23be9758d979",
   "metadata": {},
   "source": [
    "### Training and Evaluating XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e679fbd2-341d-48ec-9189-22b5382fd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9313725490196079\n"
     ]
    }
   ],
   "source": [
    "xgb_model_optimized = XGBClassifier(\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "xgb_model_optimized.fit(X_train, y_train)\n",
    "xgb_preds_optimized = xgb_model_optimized.predict(X_test)\n",
    "xgb_accuracy_optimized = accuracy_score(y_test, xgb_preds_optimized)\n",
    "\n",
    "print(\"XGBoost Accuracy:\",xgb_accuracy_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5c6f6-b1bb-4e04-a73b-91569cbad7b6",
   "metadata": {},
   "source": [
    "### Training and Evaluating Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb01e3ae-0f10-44ed-a792-8da5992427e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Random Forest Accuracy:\",rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef0bd6-54de-4776-beb5-38b626afc996",
   "metadata": {},
   "source": [
    "## Findings\n",
    "Random Forest performs best for this dataset, with higher accuracy (94.12%) and strong reliability. It effectively handles complex relationships and is not easily affected by noise. XGBoost, with an accuracy of 93.14%, also remains an effective choice, where its boosting technique can improve predictions over time.\n",
    "\n",
    "## Conclusion and Comparison with all the models \n",
    "The results show that tree-based models achieve much higher accuracy than traditional classification models. Random Forest performs the best at 94.12%, followed by XGBoost at 93.14%. In comparison, Logistic Regression (86.55%), LDA (84.03%), and Na√Øve Bayes (80.67%) have lower accuracy. This is because tree-based models can capture complex feature interactions and non-linear patterns, making them ideal when accuracy is the main priority. However, if a simpler and more interpretable model is needed, Logistic Regression or LDA can be good alternatives, even though they sacrifice some accuracy.\n",
    "Thus, tree-based models are the best option for high accuracy, while traditional models provide better interpretability with a trade-off in performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
